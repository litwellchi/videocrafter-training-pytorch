Node IP: 10.33.5.37
SLURM_PROCID: 0
[INFO] Resume from epoch 7, global step 216!
[INFO] resume from: ./overfit_macvid/checkpoints/last.ckpt
logdir:  ./overfit_macvid
Set DDP mode
Running on GPUs 0,1,2,3,4,5,6,7,
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': './overfit_macvid/checkpoints', 'filename': '{epoch:04}-{step:06}', 'verbose': True, 'save_last': True, 'every_n_epochs': 1}}
increase_log_steps:  True
Caution: Saving checkpoints every n train steps without deleting. This might require some free space.
set precision=32
lightning_config {'callbacks': {'image_logger': {'target': 'lvdm.utils.callbacks.ImageLogger', 'params': {'batch_frequency': 1000, 'max_images': 10, 'increase_log_steps': False}}, 'metrics_over_trainsteps_checkpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'filename': '{epoch:06}-{step:09}', 'save_weights_only': False, 'every_n_epochs': 300, 'every_n_train_steps': None}}}, 'trainer': {'benchmark': True, 'batch_size': 1, 'num_workers': 38, 'num_nodes': 2, 'accumulate_grad_batches': 2, 'max_epochs': 2000, 'accelerator': 'cuda', 'gpus': '0,1,2,3,4,5,6,7,', 'resume_from_checkpoint': './overfit_macvid/checkpoints/last.ckpt'}, 'modelcheckpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'every_n_epochs': 1, 'filename': '{epoch:04}-{step:06}'}}}
strategy
<pytorch_lightning.strategies.sharded.DDPShardedStrategy object at 0x155408a717f0>
accumulate_grad_batches = 2
Number of videos = 6704
Number of videos = 6704
#### Data #####
train, MaCVid, 6704
validation, MaCVid, 6704
++++ NOT USING LR SCALING ++++
Setting learning rate to 1.00e-06
Number of videos = 6704
Number of videos = 6704
Project config
model:
  base_learning_rate: 1.0e-06
  target: lvdm.models.ddpm3d.LatentDiffusion
  params:
    linear_start: 0.00085
    linear_end: 0.012
    num_timesteps_cond: 1
    timesteps: 1000
    first_stage_key: video
    cond_stage_key: caption
    cond_stage_trainable: false
    conditioning_key: crossattn
    image_size:
    - 72
    - 128
    channels: 4
    scale_by_std: false
    scale_factor: 0.18215
    use_ema: false
    uncond_type: empty_seq
    use_scale: true
    fix_scale_bug: true
    unet_config:
      target: lvdm.modules.networks.openaimodel3d.UNetModel
      params:
        in_channels: 4
        out_channels: 4
        model_channels: 320
        attention_resolutions:
        - 4
        - 2
        - 1
        num_res_blocks: 2
        channel_mult:
        - 1
        - 2
        - 4
        - 4
        num_head_channels: 64
        transformer_depth: 1
        context_dim: 1024
        use_linear: true
        use_checkpoint: true
        temporal_conv: false
        temporal_attention: true
        temporal_selfatt_only: true
        use_relative_position: true
        use_causal_attention: false
        temporal_length: 16
        addition_attention: true
        fps_cond: true
    first_stage_config:
      target: lvdm.models.autoencoder.AutoencoderKL
      params:
        embed_dim: 4
        monitor: val/rec_loss
        ddconfig:
          double_z: true
          z_channels: 4
          resolution: 512
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult:
          - 1
          - 2
          - 4
          - 4
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity
    cond_stage_config:
      target: lvdm.modules.encoders.condition.FrozenOpenCLIPEmbedder
      params:
        freeze: true
        layer: penultimate
  ckptdir: ./overfit_macvid/checkpoints
  load_from_checkpoint: /aifs4su/mmcode/videogen/share_ckpts/VideoCrafter/Text2Video-1024/model.ckpt
data:
  target: train_main.DataModuleFromConfig
  params:
    batch_size: 8
    num_workers: 16
    wrap: false
    train:
      target: lvdm.data.macvid.MaCVid
      params:
        data_root: /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85
        resolution: 256
        video_length: 16
        subset_split: all
    validation:
      target: lvdm.data.macvid.MaCVid
      params:
        data_root: /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85
        resolution: 256
        video_length: 16
        subset_split: all

Lightning config
callbacks:
  image_logger:
    target: lvdm.utils.callbacks.ImageLogger
    params:
      batch_frequency: 1000
      max_images: 10
      increase_log_steps: false
  metrics_over_trainsteps_checkpoint:
    target: pytorch_lightning.callbacks.ModelCheckpoint
    params:
      filename: '{epoch:06}-{step:09}'
      save_weights_only: false
      every_n_epochs: 300
      every_n_train_steps: null
trainer:
  benchmark: true
  batch_size: 1
  num_workers: 38
  num_nodes: 2
  accumulate_grad_batches: 2
  max_epochs: 2000
  accelerator: cuda
  gpus: 0,1,2,3,4,5,6,7,
  resume_from_checkpoint: ./overfit_macvid/checkpoints/last.ckpt
modelcheckpoint:
  target: pytorch_lightning.callbacks.ModelCheckpoint
  params:
    every_n_epochs: 1
    filename: '{epoch:04}-{step:06}'

[INFO] Resume from epoch 7, global step 216!
[INFO] resume from: ./overfit_macvid/checkpoints/last.ckpt
logdir:  ./overfit_macvid
Set DDP mode
Running on GPUs 0,1,2,3,4,5,6,7,
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': './overfit_macvid/checkpoints', 'filename': '{epoch:04}-{step:06}', 'verbose': True, 'save_last': True, 'every_n_epochs': 1}}
increase_log_steps:  True
Caution: Saving checkpoints every n train steps without deleting. This might require some free space.
set precision=32
lightning_config {'callbacks': {'image_logger': {'target': 'lvdm.utils.callbacks.ImageLogger', 'params': {'batch_frequency': 1000, 'max_images': 10, 'increase_log_steps': False}}, 'metrics_over_trainsteps_checkpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'filename': '{epoch:06}-{step:09}', 'save_weights_only': False, 'every_n_epochs': 300, 'every_n_train_steps': None}}}, 'trainer': {'benchmark': True, 'batch_size': 1, 'num_workers': 38, 'num_nodes': 2, 'accumulate_grad_batches': 2, 'max_epochs': 2000, 'accelerator': 'cuda', 'gpus': '0,1,2,3,4,5,6,7,', 'resume_from_checkpoint': './overfit_macvid/checkpoints/last.ckpt'}, 'modelcheckpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'every_n_epochs': 1, 'filename': '{epoch:04}-{step:06}'}}}
strategy
<pytorch_lightning.strategies.sharded.DDPShardedStrategy object at 0x1554102708b0>
accumulate_grad_batches = 2
Number of videos = 6704
Number of videos = 6704
#### Data #####
train, MaCVid, 6704
validation, MaCVid, 6704
++++ NOT USING LR SCALING ++++
Setting learning rate to 1.00e-06
Number of videos = 6704
Number of videos = 6704
[INFO] Resume from epoch 7, global step 216!
[INFO] resume from: ./overfit_macvid/checkpoints/last.ckpt
logdir:  ./overfit_macvid
Set DDP mode
Running on GPUs 0,1,2,3,4,5,6,7,
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': './overfit_macvid/checkpoints', 'filename': '{epoch:04}-{step:06}', 'verbose': True, 'save_last': True, 'every_n_epochs': 1}}
increase_log_steps:  True
Caution: Saving checkpoints every n train steps without deleting. This might require some free space.
set precision=32
lightning_config {'callbacks': {'image_logger': {'target': 'lvdm.utils.callbacks.ImageLogger', 'params': {'batch_frequency': 1000, 'max_images': 10, 'increase_log_steps': False}}, 'metrics_over_trainsteps_checkpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'filename': '{epoch:06}-{step:09}', 'save_weights_only': False, 'every_n_epochs': 300, 'every_n_train_steps': None}}}, 'trainer': {'benchmark': True, 'batch_size': 1, 'num_workers': 38, 'num_nodes': 2, 'accumulate_grad_batches': 2, 'max_epochs': 2000, 'accelerator': 'cuda', 'gpus': '0,1,2,3,4,5,6,7,', 'resume_from_checkpoint': './overfit_macvid/checkpoints/last.ckpt'}, 'modelcheckpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'every_n_epochs': 1, 'filename': '{epoch:04}-{step:06}'}}}
strategy
<pytorch_lightning.strategies.sharded.DDPShardedStrategy object at 0x155410271880>
accumulate_grad_batches = 2
Number of videos = 6704
Number of videos = 6704
#### Data #####
train, MaCVid, 6704
validation, MaCVid, 6704
++++ NOT USING LR SCALING ++++
Setting learning rate to 1.00e-06
Number of videos = 6704
Number of videos = 6704
[INFO] Resume from epoch 7, global step 216!
[INFO] resume from: ./overfit_macvid/checkpoints/last.ckpt
logdir:  ./overfit_macvid
Set DDP mode
Running on GPUs 0,1,2,3,4,5,6,7,
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': './overfit_macvid/checkpoints', 'filename': '{epoch:04}-{step:06}', 'verbose': True, 'save_last': True, 'every_n_epochs': 1}}
increase_log_steps:  True
Caution: Saving checkpoints every n train steps without deleting. This might require some free space.
set precision=32
lightning_config {'callbacks': {'image_logger': {'target': 'lvdm.utils.callbacks.ImageLogger', 'params': {'batch_frequency': 1000, 'max_images': 10, 'increase_log_steps': False}}, 'metrics_over_trainsteps_checkpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'filename': '{epoch:06}-{step:09}', 'save_weights_only': False, 'every_n_epochs': 300, 'every_n_train_steps': None}}}, 'trainer': {'benchmark': True, 'batch_size': 1, 'num_workers': 38, 'num_nodes': 2, 'accumulate_grad_batches': 2, 'max_epochs': 2000, 'accelerator': 'cuda', 'gpus': '0,1,2,3,4,5,6,7,', 'resume_from_checkpoint': './overfit_macvid/checkpoints/last.ckpt'}, 'modelcheckpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'every_n_epochs': 1, 'filename': '{epoch:04}-{step:06}'}}}
strategy
<pytorch_lightning.strategies.sharded.DDPShardedStrategy object at 0x1554082718b0>
accumulate_grad_batches = 2
Number of videos = 6704
Number of videos = 6704
#### Data #####
train, MaCVid, 6704
validation, MaCVid, 6704
++++ NOT USING LR SCALING ++++
Setting learning rate to 1.00e-06
Number of videos = 6704
Number of videos = 6704
[INFO] Resume from epoch 7, global step 216!
[INFO] resume from: ./overfit_macvid/checkpoints/last.ckpt
logdir:  ./overfit_macvid
Set DDP mode
Running on GPUs 0,1,2,3,4,5,6,7,
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': './overfit_macvid/checkpoints', 'filename': '{epoch:04}-{step:06}', 'verbose': True, 'save_last': True, 'every_n_epochs': 1}}
increase_log_steps:  True
Caution: Saving checkpoints every n train steps without deleting. This might require some free space.
set precision=32
lightning_config {'callbacks': {'image_logger': {'target': 'lvdm.utils.callbacks.ImageLogger', 'params': {'batch_frequency': 1000, 'max_images': 10, 'increase_log_steps': False}}, 'metrics_over_trainsteps_checkpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'filename': '{epoch:06}-{step:09}', 'save_weights_only': False, 'every_n_epochs': 300, 'every_n_train_steps': None}}}, 'trainer': {'benchmark': True, 'batch_size': 1, 'num_workers': 38, 'num_nodes': 2, 'accumulate_grad_batches': 2, 'max_epochs': 2000, 'accelerator': 'cuda', 'gpus': '0,1,2,3,4,5,6,7,', 'resume_from_checkpoint': './overfit_macvid/checkpoints/last.ckpt'}, 'modelcheckpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'every_n_epochs': 1, 'filename': '{epoch:04}-{step:06}'}}}
strategy
<pytorch_lightning.strategies.sharded.DDPShardedStrategy object at 0x15541826d9a0>
accumulate_grad_batches = 2
Number of videos = 6704
Number of videos = 6704
#### Data #####
train, MaCVid, 6704
validation, MaCVid, 6704
++++ NOT USING LR SCALING ++++
Setting learning rate to 1.00e-06
Number of videos = 6704
Number of videos = 6704
[INFO] Resume from epoch 7, global step 216!
[INFO] resume from: ./overfit_macvid/checkpoints/last.ckpt
logdir:  ./overfit_macvid
Set DDP mode
Running on GPUs 0,1,2,3,4,5,6,7,
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': './overfit_macvid/checkpoints', 'filename': '{epoch:04}-{step:06}', 'verbose': True, 'save_last': True, 'every_n_epochs': 1}}
increase_log_steps:  True
Caution: Saving checkpoints every n train steps without deleting. This might require some free space.
set precision=32
lightning_config {'callbacks': {'image_logger': {'target': 'lvdm.utils.callbacks.ImageLogger', 'params': {'batch_frequency': 1000, 'max_images': 10, 'increase_log_steps': False}}, 'metrics_over_trainsteps_checkpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'filename': '{epoch:06}-{step:09}', 'save_weights_only': False, 'every_n_epochs': 300, 'every_n_train_steps': None}}}, 'trainer': {'benchmark': True, 'batch_size': 1, 'num_workers': 38, 'num_nodes': 2, 'accumulate_grad_batches': 2, 'max_epochs': 2000, 'accelerator': 'cuda', 'gpus': '0,1,2,3,4,5,6,7,', 'resume_from_checkpoint': './overfit_macvid/checkpoints/last.ckpt'}, 'modelcheckpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'every_n_epochs': 1, 'filename': '{epoch:04}-{step:06}'}}}
strategy
<pytorch_lightning.strategies.sharded.DDPShardedStrategy object at 0x15541826f970>
accumulate_grad_batches = 2
Number of videos = 6704
Number of videos = 6704
#### Data #####
train, MaCVid, 6704
validation, MaCVid, 6704
++++ NOT USING LR SCALING ++++
Setting learning rate to 1.00e-06
Number of videos = 6704
Number of videos = 6704
[INFO] Resume from epoch 7, global step 216!
[INFO] resume from: ./overfit_macvid/checkpoints/last.ckpt
logdir:  ./overfit_macvid
Set DDP mode
Running on GPUs 0,1,2,3,4,5,6,7,
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': './overfit_macvid/checkpoints', 'filename': '{epoch:04}-{step:06}', 'verbose': True, 'save_last': True, 'every_n_epochs': 1}}
increase_log_steps:  True
Caution: Saving checkpoints every n train steps without deleting. This might require some free space.
set precision=32
[INFO] Resume from epoch 7, global step 216!
[INFO] resume from: ./overfit_macvid/checkpoints/last.ckpt
logdir:  ./overfit_macvid
Set DDP mode
Running on GPUs 0,1,2,3,4,5,6,7,
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': './overfit_macvid/checkpoints', 'filename': '{epoch:04}-{step:06}', 'verbose': True, 'save_last': True, 'every_n_epochs': 1}}
increase_log_steps:  True
Caution: Saving checkpoints every n train steps without deleting. This might require some free space.
set precision=32
lightning_config {'callbacks': {'image_logger': {'target': 'lvdm.utils.callbacks.ImageLogger', 'params': {'batch_frequency': 1000, 'max_images': 10, 'increase_log_steps': False}}, 'metrics_over_trainsteps_checkpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'filename': '{epoch:06}-{step:09}', 'save_weights_only': False, 'every_n_epochs': 300, 'every_n_train_steps': None}}}, 'trainer': {'benchmark': True, 'batch_size': 1, 'num_workers': 38, 'num_nodes': 2, 'accumulate_grad_batches': 2, 'max_epochs': 2000, 'accelerator': 'cuda', 'gpus': '0,1,2,3,4,5,6,7,', 'resume_from_checkpoint': './overfit_macvid/checkpoints/last.ckpt'}, 'modelcheckpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'every_n_epochs': 1, 'filename': '{epoch:04}-{step:06}'}}}
strategy
<pytorch_lightning.strategies.sharded.DDPShardedStrategy object at 0x15537b732880>
accumulate_grad_batches = 2
Number of videos = 6704
Number of videos = 6704
#### Data #####
train, MaCVid, 6704
validation, MaCVid, 6704
++++ NOT USING LR SCALING ++++
Setting learning rate to 1.00e-06
Number of videos = 6704
Number of videos = 6704
lightning_config {'callbacks': {'image_logger': {'target': 'lvdm.utils.callbacks.ImageLogger', 'params': {'batch_frequency': 1000, 'max_images': 10, 'increase_log_steps': False}}, 'metrics_over_trainsteps_checkpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'filename': '{epoch:06}-{step:09}', 'save_weights_only': False, 'every_n_epochs': 300, 'every_n_train_steps': None}}}, 'trainer': {'benchmark': True, 'batch_size': 1, 'num_workers': 38, 'num_nodes': 2, 'accumulate_grad_batches': 2, 'max_epochs': 2000, 'accelerator': 'cuda', 'gpus': '0,1,2,3,4,5,6,7,', 'resume_from_checkpoint': './overfit_macvid/checkpoints/last.ckpt'}, 'modelcheckpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'every_n_epochs': 1, 'filename': '{epoch:04}-{step:06}'}}}
strategy
<pytorch_lightning.strategies.sharded.DDPShardedStrategy object at 0x155418271820>
accumulate_grad_batches = 2
Number of videos = 6704
Number of videos = 6704
#### Data #####
train, MaCVid, 6704
validation, MaCVid, 6704
++++ NOT USING LR SCALING ++++
Setting learning rate to 1.00e-06
Number of videos = 6704
Number of videos = 6704
[INFO] Resume from epoch 7, global step 216!
[INFO] resume from: ./overfit_macvid/checkpoints/last.ckpt
logdir:  ./overfit_macvid
Set DDP mode
Running on GPUs 0,1,2,3,4,5,6,7,
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': './overfit_macvid/checkpoints', 'filename': '{epoch:04}-{step:06}', 'verbose': True, 'save_last': True, 'every_n_epochs': 1}}
increase_log_steps:  True
Caution: Saving checkpoints every n train steps without deleting. This might require some free space.
set precision=32
lightning_config {'callbacks': {'image_logger': {'target': 'lvdm.utils.callbacks.ImageLogger', 'params': {'batch_frequency': 1000, 'max_images': 10, 'increase_log_steps': False}}, 'metrics_over_trainsteps_checkpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'filename': '{epoch:06}-{step:09}', 'save_weights_only': False, 'every_n_epochs': 300, 'every_n_train_steps': None}}}, 'trainer': {'benchmark': True, 'batch_size': 1, 'num_workers': 38, 'num_nodes': 2, 'accumulate_grad_batches': 2, 'max_epochs': 2000, 'accelerator': 'cuda', 'gpus': '0,1,2,3,4,5,6,7,', 'resume_from_checkpoint': './overfit_macvid/checkpoints/last.ckpt'}, 'modelcheckpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'every_n_epochs': 1, 'filename': '{epoch:04}-{step:06}'}}}
strategy
<pytorch_lightning.strategies.sharded.DDPShardedStrategy object at 0x155400a6d9d0>
accumulate_grad_batches = 2
Number of videos = 6704
Number of videos = 6704
#### Data #####
train, MaCVid, 6704
validation, MaCVid, 6704
++++ NOT USING LR SCALING ++++
Setting learning rate to 1.00e-06
Number of videos = 6704
Number of videos = 6704
[INFO] Resume from epoch 7, global step 216!
[INFO] resume from: ./overfit_macvid/checkpoints/last.ckpt
logdir:  ./overfit_macvid
Set DDP mode
Running on GPUs 0,1,2,3,4,5,6,7,
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': './overfit_macvid/checkpoints', 'filename': '{epoch:04}-{step:06}', 'verbose': True, 'save_last': True, 'every_n_epochs': 1}}
increase_log_steps:  True
Caution: Saving checkpoints every n train steps without deleting. This might require some free space.
set precision=32
lightning_config {'callbacks': {'image_logger': {'target': 'lvdm.utils.callbacks.ImageLogger', 'params': {'batch_frequency': 1000, 'max_images': 10, 'increase_log_steps': False}}, 'metrics_over_trainsteps_checkpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'filename': '{epoch:06}-{step:09}', 'save_weights_only': False, 'every_n_epochs': 300, 'every_n_train_steps': None}}}, 'trainer': {'benchmark': True, 'batch_size': 1, 'num_workers': 38, 'num_nodes': 2, 'accumulate_grad_batches': 2, 'max_epochs': 2000, 'accelerator': 'cuda', 'gpus': '0,1,2,3,4,5,6,7,', 'resume_from_checkpoint': './overfit_macvid/checkpoints/last.ckpt'}, 'modelcheckpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'every_n_epochs': 1, 'filename': '{epoch:04}-{step:06}'}}}
strategy
<pytorch_lightning.strategies.sharded.DDPShardedStrategy object at 0x15537b7438e0>
accumulate_grad_batches = 2
Number of videos = 6704
Number of videos = 6704
#### Data #####
train, MaCVid, 6704
validation, MaCVid, 6704
++++ NOT USING LR SCALING ++++
Setting learning rate to 1.00e-06
Number of videos = 6704
Number of videos = 6704
[INFO] Resume from epoch 7, global step 216!
[INFO] resume from: ./overfit_macvid/checkpoints/last.ckpt
logdir:  ./overfit_macvid
Set DDP mode
Running on GPUs 0,1,2,3,4,5,6,7,
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': './overfit_macvid/checkpoints', 'filename': '{epoch:04}-{step:06}', 'verbose': True, 'save_last': True, 'every_n_epochs': 1}}
increase_log_steps:  True
Caution: Saving checkpoints every n train steps without deleting. This might require some free space.
set precision=32
lightning_config {'callbacks': {'image_logger': {'target': 'lvdm.utils.callbacks.ImageLogger', 'params': {'batch_frequency': 1000, 'max_images': 10, 'increase_log_steps': False}}, 'metrics_over_trainsteps_checkpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'filename': '{epoch:06}-{step:09}', 'save_weights_only': False, 'every_n_epochs': 300, 'every_n_train_steps': None}}}, 'trainer': {'benchmark': True, 'batch_size': 1, 'num_workers': 38, 'num_nodes': 2, 'accumulate_grad_batches': 2, 'max_epochs': 2000, 'accelerator': 'cuda', 'gpus': '0,1,2,3,4,5,6,7,', 'resume_from_checkpoint': './overfit_macvid/checkpoints/last.ckpt'}, 'modelcheckpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'every_n_epochs': 1, 'filename': '{epoch:04}-{step:06}'}}}
strategy
<pytorch_lightning.strategies.sharded.DDPShardedStrategy object at 0x155408271970>
accumulate_grad_batches = 2
Number of videos = 6704
Number of videos = 6704
#### Data #####
train, MaCVid, 6704
validation, MaCVid, 6704
++++ NOT USING LR SCALING ++++
Setting learning rate to 1.00e-06
Number of videos = 6704
Number of videos = 6704
[INFO] Resume from epoch 7, global step 216!
[INFO] resume from: ./overfit_macvid/checkpoints/last.ckpt
logdir:  ./overfit_macvid
Set DDP mode
Running on GPUs 0,1,2,3,4,5,6,7,
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': './overfit_macvid/checkpoints', 'filename': '{epoch:04}-{step:06}', 'verbose': True, 'save_last': True, 'every_n_epochs': 1}}
increase_log_steps:  True
Caution: Saving checkpoints every n train steps without deleting. This might require some free space.
set precision=32
lightning_config {'callbacks': {'image_logger': {'target': 'lvdm.utils.callbacks.ImageLogger', 'params': {'batch_frequency': 1000, 'max_images': 10, 'increase_log_steps': False}}, 'metrics_over_trainsteps_checkpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'filename': '{epoch:06}-{step:09}', 'save_weights_only': False, 'every_n_epochs': 300, 'every_n_train_steps': None}}}, 'trainer': {'benchmark': True, 'batch_size': 1, 'num_workers': 38, 'num_nodes': 2, 'accumulate_grad_batches': 2, 'max_epochs': 2000, 'accelerator': 'cuda', 'gpus': '0,1,2,3,4,5,6,7,', 'resume_from_checkpoint': './overfit_macvid/checkpoints/last.ckpt'}, 'modelcheckpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'every_n_epochs': 1, 'filename': '{epoch:04}-{step:06}'}}}
strategy
<pytorch_lightning.strategies.sharded.DDPShardedStrategy object at 0x155410271820>
accumulate_grad_batches = 2
Number of videos = 6704
Number of videos = 6704
#### Data #####
train, MaCVid, 6704
validation, MaCVid, 6704
++++ NOT USING LR SCALING ++++
Setting learning rate to 1.00e-06
Number of videos = 6704
Number of videos = 6704
[INFO] Resume from epoch 7, global step 216!
[INFO] resume from: ./overfit_macvid/checkpoints/last.ckpt
logdir:  ./overfit_macvid
Set DDP mode
Running on GPUs 0,1,2,3,4,5,6,7,
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': './overfit_macvid/checkpoints', 'filename': '{epoch:04}-{step:06}', 'verbose': True, 'save_last': True, 'every_n_epochs': 1}}
increase_log_steps:  True
Caution: Saving checkpoints every n train steps without deleting. This might require some free space.
set precision=32
lightning_config {'callbacks': {'image_logger': {'target': 'lvdm.utils.callbacks.ImageLogger', 'params': {'batch_frequency': 1000, 'max_images': 10, 'increase_log_steps': False}}, 'metrics_over_trainsteps_checkpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'filename': '{epoch:06}-{step:09}', 'save_weights_only': False, 'every_n_epochs': 300, 'every_n_train_steps': None}}}, 'trainer': {'benchmark': True, 'batch_size': 1, 'num_workers': 38, 'num_nodes': 2, 'accumulate_grad_batches': 2, 'max_epochs': 2000, 'accelerator': 'cuda', 'gpus': '0,1,2,3,4,5,6,7,', 'resume_from_checkpoint': './overfit_macvid/checkpoints/last.ckpt'}, 'modelcheckpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'every_n_epochs': 1, 'filename': '{epoch:04}-{step:06}'}}}
strategy
<pytorch_lightning.strategies.sharded.DDPShardedStrategy object at 0x155408a6d8e0>
accumulate_grad_batches = 2
Number of videos = 6704
Number of videos = 6704
#### Data #####
train, MaCVid, 6704
validation, MaCVid, 6704
++++ NOT USING LR SCALING ++++
Setting learning rate to 1.00e-06
Number of videos = 6704
Number of videos = 6704
[INFO] Resume from epoch 7, global step 216!
[INFO] resume from: ./overfit_macvid/checkpoints/last.ckpt
logdir:  ./overfit_macvid
Set DDP mode
Running on GPUs 0,1,2,3,4,5,6,7,
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': './overfit_macvid/checkpoints', 'filename': '{epoch:04}-{step:06}', 'verbose': True, 'save_last': True, 'every_n_epochs': 1}}
increase_log_steps:  True
Caution: Saving checkpoints every n train steps without deleting. This might require some free space.
set precision=32
lightning_config {'callbacks': {'image_logger': {'target': 'lvdm.utils.callbacks.ImageLogger', 'params': {'batch_frequency': 1000, 'max_images': 10, 'increase_log_steps': False}}, 'metrics_over_trainsteps_checkpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'filename': '{epoch:06}-{step:09}', 'save_weights_only': False, 'every_n_epochs': 300, 'every_n_train_steps': None}}}, 'trainer': {'benchmark': True, 'batch_size': 1, 'num_workers': 38, 'num_nodes': 2, 'accumulate_grad_batches': 2, 'max_epochs': 2000, 'accelerator': 'cuda', 'gpus': '0,1,2,3,4,5,6,7,', 'resume_from_checkpoint': './overfit_macvid/checkpoints/last.ckpt'}, 'modelcheckpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'every_n_epochs': 1, 'filename': '{epoch:04}-{step:06}'}}}
strategy
<pytorch_lightning.strategies.sharded.DDPShardedStrategy object at 0x155400a6d8b0>
accumulate_grad_batches = 2
Number of videos = 6704
Number of videos = 6704
#### Data #####
train, MaCVid, 6704
validation, MaCVid, 6704
++++ NOT USING LR SCALING ++++
Setting learning rate to 1.00e-06
Number of videos = 6704
Number of videos = 6704
[INFO] Resume from epoch 7, global step 216!
[INFO] resume from: ./overfit_macvid/checkpoints/last.ckpt
logdir:  ./overfit_macvid
Set DDP mode
Running on GPUs 0,1,2,3,4,5,6,7,
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': './overfit_macvid/checkpoints', 'filename': '{epoch:04}-{step:06}', 'verbose': True, 'save_last': True, 'every_n_epochs': 1}}
increase_log_steps:  True
Caution: Saving checkpoints every n train steps without deleting. This might require some free space.
set precision=32
lightning_config {'callbacks': {'image_logger': {'target': 'lvdm.utils.callbacks.ImageLogger', 'params': {'batch_frequency': 1000, 'max_images': 10, 'increase_log_steps': False}}, 'metrics_over_trainsteps_checkpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'filename': '{epoch:06}-{step:09}', 'save_weights_only': False, 'every_n_epochs': 300, 'every_n_train_steps': None}}}, 'trainer': {'benchmark': True, 'batch_size': 1, 'num_workers': 38, 'num_nodes': 2, 'accumulate_grad_batches': 2, 'max_epochs': 2000, 'accelerator': 'cuda', 'gpus': '0,1,2,3,4,5,6,7,', 'resume_from_checkpoint': './overfit_macvid/checkpoints/last.ckpt'}, 'modelcheckpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'every_n_epochs': 1, 'filename': '{epoch:04}-{step:06}'}}}
strategy
<pytorch_lightning.strategies.sharded.DDPShardedStrategy object at 0x155400a6f910>
accumulate_grad_batches = 2
Number of videos = 6704
Number of videos = 6704
#### Data #####
train, MaCVid, 6704
validation, MaCVid, 6704
++++ NOT USING LR SCALING ++++
Setting learning rate to 1.00e-06
Number of videos = 6704
Number of videos = 6704
[INFO] Resume from epoch 7, global step 216!
[INFO] resume from: ./overfit_macvid/checkpoints/last.ckpt
logdir:  ./overfit_macvid
Set DDP mode
Running on GPUs 0,1,2,3,4,5,6,7,
AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.
Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': './overfit_macvid/checkpoints', 'filename': '{epoch:04}-{step:06}', 'verbose': True, 'save_last': True, 'every_n_epochs': 1}}
increase_log_steps:  True
Caution: Saving checkpoints every n train steps without deleting. This might require some free space.
set precision=32
lightning_config {'callbacks': {'image_logger': {'target': 'lvdm.utils.callbacks.ImageLogger', 'params': {'batch_frequency': 1000, 'max_images': 10, 'increase_log_steps': False}}, 'metrics_over_trainsteps_checkpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'filename': '{epoch:06}-{step:09}', 'save_weights_only': False, 'every_n_epochs': 300, 'every_n_train_steps': None}}}, 'trainer': {'benchmark': True, 'batch_size': 1, 'num_workers': 38, 'num_nodes': 2, 'accumulate_grad_batches': 2, 'max_epochs': 2000, 'accelerator': 'cuda', 'gpus': '0,1,2,3,4,5,6,7,', 'resume_from_checkpoint': './overfit_macvid/checkpoints/last.ckpt'}, 'modelcheckpoint': {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'every_n_epochs': 1, 'filename': '{epoch:04}-{step:06}'}}}
strategy
<pytorch_lightning.strategies.sharded.DDPShardedStrategy object at 0x15537b730760>
accumulate_grad_batches = 2
Number of videos = 6704
Number of videos = 6704
#### Data #####
train, MaCVid, 6704
validation, MaCVid, 6704
++++ NOT USING LR SCALING ++++
Setting learning rate to 1.00e-06
Number of videos = 6704
Number of videos = 6704
Sanity Checking: 0it [00:00, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:08<00:08,  8.94s/it]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:10<00:00,  5.42s/it]                                                                           Training: 53it [00:00, ?it/s]Training:   0%|          | 0/106 [00:00<00:00, -3221711.77it/s]Epoch 8:   0%|          | 0/106 [00:00<?, ?it/s]               Epoch 8:   1%|          | 1/106 [00:26<45:52, 26.21s/it]Epoch 8:   1%|          | 1/106 [00:26<45:52, 26.21s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00592, train/loss_step=1.000, global_step=216.0]Epoch 8:   2%|▏         | 2/106 [00:29<25:23, 14.65s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00592, train/loss_step=1.000, global_step=216.0]Epoch 8:   2%|▏         | 2/106 [00:29<25:26, 14.67s/it, loss=1, v_num=1, train/loss_simple_step=0.997, train/loss_vlb_step=0.00559, train/loss_step=0.997, global_step=216.0]Epoch 8:   3%|▎         | 3/106 [00:31<18:13, 10.61s/it, loss=1, v_num=1, train/loss_simple_step=0.997, train/loss_vlb_step=0.00559, train/loss_step=0.997, global_step=216.0]Epoch 8:   3%|▎         | 3/106 [00:32<18:26, 10.75s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.0067, train/loss_step=1.000, global_step=217.0] Epoch 8:   4%|▍         | 4/106 [00:35<14:59,  8.81s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.0067, train/loss_step=1.000, global_step=217.0]Epoch 8:   4%|▍         | 4/106 [00:35<14:59,  8.82s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00462, train/loss_step=1.000, global_step=217.0]Epoch 8:   5%|▍         | 5/106 [00:37<12:43,  7.56s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00462, train/loss_step=1.000, global_step=217.0]Epoch 8:   5%|▍         | 5/106 [00:38<12:51,  7.64s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00438, train/loss_step=1.010, global_step=218.0]Epoch 8:   6%|▌         | 6/106 [00:41<11:25,  6.85s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00438, train/loss_step=1.010, global_step=218.0]Epoch 8:   6%|▌         | 6/106 [00:41<11:25,  6.86s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.004, train/loss_step=1.000, global_step=218.0]  Epoch 8:   7%|▋         | 7/106 [00:43<10:17,  6.24s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.004, train/loss_step=1.000, global_step=218.0]Epoch 8:   7%|▋         | 7/106 [00:44<10:23,  6.30s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00477, train/loss_step=1.000, global_step=219.0]Epoch 8:   8%|▊         | 8/106 [00:46<09:35,  5.87s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00477, train/loss_step=1.000, global_step=219.0]Epoch 8:   8%|▊         | 8/106 [00:47<09:36,  5.88s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00392, train/loss_step=1.000, global_step=219.0]Epoch 8:   8%|▊         | 9/106 [00:49<08:53,  5.50s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00392, train/loss_step=1.000, global_step=219.0]Epoch 8:   8%|▊         | 9/106 [00:49<08:58,  5.55s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00423, train/loss_step=1.000, global_step=220.0]Epoch 8:   9%|▉         | 10/106 [00:52<08:27,  5.29s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00423, train/loss_step=1.000, global_step=220.0]Epoch 8:   9%|▉         | 10/106 [00:52<08:27,  5.29s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00955, train/loss_step=1.000, global_step=220.0]Epoch 8:  10%|█         | 11/106 [00:55<07:58,  5.04s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00955, train/loss_step=1.000, global_step=220.0]Epoch 8:  10%|█         | 11/106 [00:55<08:02,  5.07s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00481, train/loss_step=1.000, global_step=221.0]Epoch 8:  11%|█▏        | 12/106 [00:58<07:40,  4.90s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00481, train/loss_step=1.000, global_step=221.0]Epoch 8:  11%|█▏        | 12/106 [00:58<07:40,  4.90s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00435, train/loss_step=1.000, global_step=221.0]Epoch 8:  12%|█▏        | 13/106 [01:01<07:18,  4.72s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00435, train/loss_step=1.000, global_step=221.0]Epoch 8:  12%|█▏        | 13/106 [01:01<07:21,  4.75s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00811, train/loss_step=1.000, global_step=222.0]Epoch 8:  13%|█▎        | 14/106 [01:04<07:04,  4.62s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00811, train/loss_step=1.000, global_step=222.0]Epoch 8:  13%|█▎        | 14/106 [01:04<07:05,  4.62s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00443, train/loss_step=1.000, global_step=222.0]Epoch 8:  14%|█▍        | 15/106 [01:07<06:47,  4.48s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00443, train/loss_step=1.000, global_step=222.0]Epoch 8:  14%|█▍        | 15/106 [01:07<06:49,  4.50s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00445, train/loss_step=1.000, global_step=223.0]Epoch 8:  15%|█▌        | 16/106 [01:10<06:36,  4.41s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00445, train/loss_step=1.000, global_step=223.0]Epoch 8:  15%|█▌        | 16/106 [01:10<06:36,  4.41s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.00442, train/loss_step=0.999, global_step=223.0]Epoch 8:  16%|█▌        | 17/106 [01:13<06:22,  4.30s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.00442, train/loss_step=0.999, global_step=223.0]Epoch 8:  16%|█▌        | 17/106 [01:13<06:24,  4.32s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.00766, train/loss_step=0.999, global_step=224.0]Epoch 8:  17%|█▋        | 18/106 [01:16<06:13,  4.25s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.00766, train/loss_step=0.999, global_step=224.0]Epoch 8:  17%|█▋        | 18/106 [01:16<06:13,  4.25s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00384, train/loss_step=1.000, global_step=224.0]Epoch 8:  18%|█▊        | 19/106 [01:18<06:01,  4.15s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00384, train/loss_step=1.000, global_step=224.0]Epoch 8:  18%|█▊        | 19/106 [01:19<06:03,  4.18s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00433, train/loss_step=1.000, global_step=225.0]Epoch 8:  19%|█▉        | 20/106 [01:22<05:54,  4.12s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00433, train/loss_step=1.000, global_step=225.0]Epoch 8:  19%|█▉        | 20/106 [01:22<05:54,  4.12s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00421, train/loss_step=1.000, global_step=225.0]Epoch 8:  20%|█▉        | 21/106 [01:24<05:44,  4.05s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00421, train/loss_step=1.000, global_step=225.0]Epoch 8:  20%|█▉        | 21/106 [01:25<05:45,  4.07s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.00483, train/loss_step=0.999, global_step=226.0]Epoch 8:  21%|██        | 22/106 [01:28<05:37,  4.01s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.00483, train/loss_step=0.999, global_step=226.0]Epoch 8:  21%|██        | 22/106 [01:28<05:37,  4.02s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00447, train/loss_step=1.000, global_step=226.0]Epoch 8:  22%|██▏       | 23/106 [01:30<05:27,  3.95s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00447, train/loss_step=1.000, global_step=226.0]Epoch 8:  22%|██▏       | 23/106 [01:31<05:29,  3.97s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00576, train/loss_step=1.000, global_step=227.0]Epoch 8:  23%|██▎       | 24/106 [01:34<05:21,  3.92s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00576, train/loss_step=1.000, global_step=227.0]Epoch 8:  23%|██▎       | 24/106 [01:34<05:21,  3.92s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00939, train/loss_step=1.000, global_step=227.0]Epoch 8:  24%|██▎       | 25/106 [01:36<05:13,  3.87s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00939, train/loss_step=1.000, global_step=227.0]Epoch 8:  24%|██▎       | 25/106 [01:37<05:14,  3.88s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.0416, train/loss_step=1.000, global_step=228.0] Epoch 8:  25%|██▍       | 26/106 [01:40<05:07,  3.85s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.0416, train/loss_step=1.000, global_step=228.0]Epoch 8:  25%|██▍       | 26/106 [01:40<05:07,  3.85s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00453, train/loss_step=1.000, global_step=228.0]Epoch 8:  25%|██▌       | 27/106 [01:42<04:59,  3.80s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00453, train/loss_step=1.000, global_step=228.0]Epoch 8:  25%|██▌       | 27/106 [01:42<05:01,  3.81s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00514, train/loss_step=1.000, global_step=229.0]Epoch 8:  26%|██▋       | 28/106 [01:45<04:54,  3.78s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00514, train/loss_step=1.000, global_step=229.0]Epoch 8:  26%|██▋       | 28/106 [01:45<04:54,  3.78s/it, loss=1, v_num=1, train/loss_simple_step=0.996, train/loss_vlb_step=0.00512, train/loss_step=0.996, global_step=229.0]Epoch 8:  27%|██▋       | 29/106 [01:48<04:47,  3.74s/it, loss=1, v_num=1, train/loss_simple_step=0.996, train/loss_vlb_step=0.00512, train/loss_step=0.996, global_step=229.0]Epoch 8:  27%|██▋       | 29/106 [01:48<04:48,  3.75s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00479, train/loss_step=1.000, global_step=230.0]Epoch 8:  28%|██▊       | 30/106 [01:51<04:42,  3.72s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00479, train/loss_step=1.000, global_step=230.0]Epoch 8:  28%|██▊       | 30/106 [01:51<04:43,  3.72s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.0046, train/loss_step=1.000, global_step=230.0] Epoch 8:  29%|██▉       | 31/106 [01:54<04:36,  3.68s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.0046, train/loss_step=1.000, global_step=230.0]Epoch 8:  29%|██▉       | 31/106 [01:54<04:37,  3.70s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00923, train/loss_step=1.000, global_step=231.0]Epoch 8:  30%|███       | 32/106 [01:57<04:31,  3.67s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00923, train/loss_step=1.000, global_step=231.0]Epoch 8:  30%|███       | 32/106 [01:57<04:31,  3.67s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00561, train/loss_step=1.000, global_step=231.0]Epoch 8:  31%|███       | 33/106 [02:00<04:25,  3.64s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00561, train/loss_step=1.000, global_step=231.0]Epoch 8:  31%|███       | 33/106 [02:00<04:26,  3.65s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.0037, train/loss_step=0.999, global_step=232.0] Epoch 8:  32%|███▏      | 34/106 [02:03<04:21,  3.63s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.0037, train/loss_step=0.999, global_step=232.0]Epoch 8:  32%|███▏      | 34/106 [02:03<04:21,  3.63s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00408, train/loss_step=1.000, global_step=232.0]Epoch 8:  33%|███▎      | 35/106 [02:05<04:15,  3.60s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00408, train/loss_step=1.000, global_step=232.0]Epoch 8:  33%|███▎      | 35/106 [02:06<04:16,  3.61s/it, loss=1, v_num=1, train/loss_simple_step=0.998, train/loss_vlb_step=0.0057, train/loss_step=0.998, global_step=233.0] Epoch 8:  34%|███▍      | 36/106 [02:09<04:11,  3.59s/it, loss=1, v_num=1, train/loss_simple_step=0.998, train/loss_vlb_step=0.0057, train/loss_step=0.998, global_step=233.0]Epoch 8:  34%|███▍      | 36/106 [02:09<04:11,  3.59s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.0194, train/loss_step=1.000, global_step=233.0]Epoch 8:  35%|███▍      | 37/106 [02:11<04:05,  3.56s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.0194, train/loss_step=1.000, global_step=233.0]Epoch 8:  35%|███▍      | 37/106 [02:12<04:06,  3.57s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00442, train/loss_step=1.000, global_step=234.0]Epoch 8:  36%|███▌      | 38/106 [02:15<04:01,  3.56s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00442, train/loss_step=1.000, global_step=234.0]Epoch 8:  36%|███▌      | 38/106 [02:15<04:01,  3.56s/it, loss=1, v_num=1, train/loss_simple_step=0.997, train/loss_vlb_step=0.00374, train/loss_step=0.997, global_step=234.0]Epoch 8:  37%|███▋      | 39/106 [02:17<03:56,  3.53s/it, loss=1, v_num=1, train/loss_simple_step=0.997, train/loss_vlb_step=0.00374, train/loss_step=0.997, global_step=234.0]Epoch 8:  37%|███▋      | 39/106 [02:18<03:57,  3.54s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00467, train/loss_step=1.000, global_step=235.0]Epoch 8:  38%|███▊      | 40/106 [02:20<03:52,  3.52s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00467, train/loss_step=1.000, global_step=235.0]Epoch 8:  38%|███▊      | 40/106 [02:20<03:52,  3.52s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00532, train/loss_step=1.000, global_step=235.0]Epoch 8:  39%|███▊      | 41/106 [02:23<03:47,  3.50s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00532, train/loss_step=1.000, global_step=235.0]Epoch 8:  39%|███▊      | 41/106 [02:23<03:48,  3.51s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00453, train/loss_step=1.000, global_step=236.0]Epoch 8:  40%|███▉      | 42/106 [02:26<03:43,  3.50s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00453, train/loss_step=1.000, global_step=236.0]Epoch 8:  40%|███▉      | 42/106 [02:26<03:43,  3.50s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00569, train/loss_step=1.000, global_step=236.0]Epoch 8:  41%|████      | 43/106 [02:29<03:38,  3.47s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00569, train/loss_step=1.000, global_step=236.0]Epoch 8:  41%|████      | 43/106 [02:29<03:39,  3.48s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00877, train/loss_step=1.000, global_step=237.0]Epoch 8:  42%|████▏     | 44/106 [02:32<03:35,  3.47s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00877, train/loss_step=1.000, global_step=237.0]Epoch 8:  42%|████▏     | 44/106 [02:32<03:35,  3.47s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00484, train/loss_step=1.000, global_step=237.0]Epoch 8:  42%|████▏     | 45/106 [02:35<03:30,  3.45s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00484, train/loss_step=1.000, global_step=237.0]Epoch 8:  42%|████▏     | 45/106 [02:35<03:30,  3.46s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.00417, train/loss_step=0.999, global_step=238.0]Epoch 8:  43%|████▎     | 46/106 [02:38<03:26,  3.45s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.00417, train/loss_step=0.999, global_step=238.0]Epoch 8:  43%|████▎     | 46/106 [02:38<03:26,  3.45s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.006, train/loss_step=0.999, global_step=238.0]  Epoch 8:  44%|████▍     | 47/106 [02:41<03:22,  3.43s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.006, train/loss_step=0.999, global_step=238.0]Epoch 8:  44%|████▍     | 47/106 [02:41<03:22,  3.43s/it, loss=1, v_num=1, train/loss_simple_step=0.997, train/loss_vlb_step=0.004, train/loss_step=0.997, global_step=239.0]Epoch 8:  45%|████▌     | 48/106 [02:44<03:18,  3.42s/it, loss=1, v_num=1, train/loss_simple_step=0.997, train/loss_vlb_step=0.004, train/loss_step=0.997, global_step=239.0]Epoch 8:  45%|████▌     | 48/106 [02:44<03:18,  3.42s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00374, train/loss_step=1.000, global_step=239.0]Epoch 8:  46%|████▌     | 49/106 [02:46<03:14,  3.41s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00374, train/loss_step=1.000, global_step=239.0]Epoch 8:  46%|████▌     | 49/106 [02:47<03:14,  3.41s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.00603, train/loss_step=0.999, global_step=240.0]Epoch 8:  47%|████▋     | 50/106 [02:50<03:10,  3.40s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.00603, train/loss_step=0.999, global_step=240.0]Epoch 8:  47%|████▋     | 50/106 [02:50<03:10,  3.40s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00434, train/loss_step=1.000, global_step=240.0]Epoch 8:  48%|████▊     | 51/106 [02:52<03:06,  3.39s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00434, train/loss_step=1.000, global_step=240.0]Epoch 8:  48%|████▊     | 51/106 [02:53<03:06,  3.39s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00448, train/loss_step=1.000, global_step=241.0]Epoch 8:  49%|████▉     | 52/106 [02:56<03:02,  3.39s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00448, train/loss_step=1.000, global_step=241.0]Epoch 8:  49%|████▉     | 52/106 [02:56<03:02,  3.39s/it, loss=1, v_num=1, train/loss_simple_step=0.997, train/loss_vlb_step=0.00538, train/loss_step=0.997, global_step=241.0]Epoch 8:  50%|█████     | 53/106 [03:01<03:01,  3.43s/it, loss=1, v_num=1, train/loss_simple_step=0.997, train/loss_Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvTxAShSH_U_0000002.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvweaacTsTI_0000018.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvweaacTsTI_0000017.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zyscRpM7c9E_0000018.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zw9vQctOYH4_0000075.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zw9vQctOYH4_0000078.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zyscRpM7c9E_0000016.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvweaacTsTI_0000015.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zyscRpM7c9E_0000017.mp4
vlb_step=0.00538, train/loss_step=0.997, global_step=241.0]Epoch 8:  50%|█████     | 53/106 [03:01<03:01,  3.43s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/53 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/53 [00:00<?, ?it/s][A
Validation DataLoader 0:   2%|▏         | 1/53 [00:02<01:49,  2.11s/it][AEpoch 8:  51%|█████     | 54/106 [03:22<03:14,  3.74s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:   4%|▍         | 2/53 [00:04<01:43,  2.02s/it][AEpoch 8:  52%|█████▏    | 55/106 [03:23<03:09,  3.71s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:   6%|▌         | 3/53 [00:05<01:39,  1.99s/it][AEpoch 8:  53%|█████▎    | 56/106 [03:25<03:03,  3.68s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:   8%|▊         | 4/53 [00:08<01:40,  2.05s/it][AEpoch 8:  54%|█████▍    | 57/106 [03:28<02:58,  3.65s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:   9%|▉         | 5/53 [00:10<01:37,  2.03s/it][AEpoch 8:  55%|█████▍    | 58/106 [03:30<02:53,  3.62s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  11%|█▏        | 6/53 [00:12<01:34,  2.01s/it][AEpoch 8:  56%|█████▌    | 59/106 [03:32<02:48,  3.59s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  13%|█▎        | 7/53 [00:14<01:32,  2.00s/it][AEpoch 8:  57%|█████▋    | 60/106 [03:33<02:44,  3.57s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  15%|█▌        | 8/53 [00:15<01:29,  1.99s/it][AEpoch 8:  58%|█████▊    | 61/106 [03:35<02:39,  3.54s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  17%|█▋        | 9/53 [00:17<01:27,  1.99s/it][AEpoch 8:  58%|█████▊    | 62/106 [03:37<02:34,  3.51s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  19%|█▉        | 10/53 [00:19<01:25,  1.98s/it][AEpoch 8:  59%|█████▉    | 63/106 [03:39<02:30,  3.49s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  21%|██        | 11/53 [00:21<01:23,  1.98s/it][AEpoch 8:  60%|██████    | 64/106 [03:41<02:25,  3.46s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  23%|██▎       | 12/53 [00:23<01:20,  1.97s/it][AEpoch 8:  61%|██████▏   | 65/106 [03:43<02:21,  3.44s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  25%|██▍       | 13/53 [00:25<01:18,  1.97s/it][AEpoch 8:  62%|██████▏   | 66/106 [03:45<02:16,  3.42s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  26%|██▋       | 14/53 [00:27<01:16,  1.97s/it][AEpoch 8:  63%|██████▎   | 67/106 [03:47<02:12,  3.40s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  28%|██▊       | 15/53 [00:29<01:14,  1.97s/it][AEpoch 8:  64%|██████▍   | 68/106 [03:49<02:08,  3.37s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  30%|███       | 16/53 [00:31<01:12,  1.97s/it][AEpoch 8:  65%|██████▌   | 69/106 [03:51<02:04,  3.35s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  32%|███▏      | 17/53 [00:33<01:10,  1.97s/it][AEpoch 8:  66%|██████▌   | 70/106 [03:53<02:00,  3.33s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  34%|███▍      | 18/53 [00:35<01:08,  1.97s/it][AEpoch 8:  67%|██████▋   | 71/106 [03:55<01:56,  3.31s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  36%|███▌      | 19/53 [00:37<01:06,  1.96s/it][AEpoch 8:  68%|██████▊   | 72/106 [03:57<01:52,  3.30s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  38%|███▊      | 20/53 [00:39<01:04,  1.96s/it][AEpoch 8:  69%|██████▉   | 73/106 [03:59<01:48,  3.28s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  40%|███▉      | 21/53 [00:41<01:02,  1.96s/it][AEpoch 8:  70%|██████▉   | 74/106 [04:01<01:44,  3.26s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  42%|████▏     | 22/53 [00:43<01:00,  1.96s/it][AEpoch 8:  71%|███████   | 75/106 [04:03<01:40,  3.24s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  43%|████▎     | 23/53 [00:45<00:58,  1.96s/it][AEpoch 8:  72%|███████▏  | 76/106 [04:04<01:36,  3.22s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  45%|████▌     | 24/53 [00:47<00:56,  1.96s/it][AEpoch 8:  73%|███████▎  | 77/106 [04:06<01:33,  3.21s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  47%|████▋     | 25/53 [00:48<00:54,  1.96s/it][AEpoch 8:  74%|███████▎  | 78/106 [04:08<01:29,  3.19s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  49%|████▉     | 26/53 [00:50<00:52,  1.96s/it][AEpoch 8:  75%|███████▍  | 79/106 [04:10<01:25,  3.17s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  51%|█████     | 27/53 [00:52<00:50,  1.95s/it][AEpoch 8:  75%|███████▌  | 80/106 [04:12<01:22,  3.16s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  53%|█████▎    | 28/53 [00:54<00:48,  1.95s/it][AEpoch 8:  76%|███████▋  | 81/106 [04:14<01:18,  3.14s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  55%|█████▍    | 29/53 [00:56<00:46,  1.95s/it][AEpoch 8:  77%|███████▋  | 82/106 [04:16<01:15,  3.13s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  57%|█████▋    | 30/53 [00:58<00:44,  1.95s/it][AEpoch 8:  78%|███████▊  | 83/106 [04:18<01:11,  3.11s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  58%|█████▊    | 31/53 [01:00<00:42,  1.95s/it][AEpoch 8:  79%|███████▉  | 84/106 [04:20<01:08,  3.10s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  60%|██████    | 32/53 [01:02<00:40,  1.95s/it][AEpoch 8:  80%|████████  | 85/106 [04:22<01:04,  3.09s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  62%|██████▏   | 33/53 [01:04<00:38,  1.95s/it][AEpoch 8:  81%|████████  | 86/106 [04:24<01:01,  3.07s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  64%|██████▍   | 34/53 [01:06<00:37,  1.95s/it][AEpoch 8:  82%|████████▏ | 87/106 [04:26<00:58,  3.06s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  66%|██████▌   | 35/53 [01:08<00:35,  1.95s/it][AEpoch 8:  83%|████████▎ | 88/106 [04:28<00:54,  3.05s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  68%|██████▊   | 36/53 [01:10<00:33,  1.95s/it][AEpoch 8:  84%|████████▍ | 89/106 [04:30<00:51,  3.03s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  70%|██████▉   | 37/53 [01:12<00:31,  1.95s/it][AEpoch 8:  85%|████████▍ | 90/106 [04:31<00:48,  3.02s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  72%|███████▏  | 38/53 [01:13<00:29,  1.95s/it][AEpoch 8:  86%|████████▌ | 91/106 [04:33<00:45,  3.01s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  74%|███████▎  | 39/53 [01:15<00:27,  1.95s/it][AEpoch 8:  87%|████████▋ | 92/106 [04:35<00:41,  3.00s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  75%|███████▌  | 40/53 [01:17<00:25,  1.95s/it][AEpoch 8:  88%|████████▊ | 93/106 [04:37<00:38,  2.99s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  77%|███████▋  | 41/53 [01:19<00:23,  1.95s/it][AEpoch 8:  89%|████████▊ | 94/106 [04:39<00:35,  2.98s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  79%|███████▉  | 42/53 [01:21<00:21,  1.95s/it][AEpoch 8:  90%|████████▉ | 95/106 [04:41<00:32,  2.96s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  81%|████████  | 43/53 [01:23<00:19,  1.94s/it][AEpoch 8:  91%|█████████ | 96/106 [04:43<00:29,  2.95s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  83%|████████▎ | 44/53 [01:25<00:17,  1.94s/it][AEpoch 8:  92%|█████████▏| 97/106 [04:45<00:26,  2.94s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  85%|████████▍ | 45/53 [01:27<00:15,  1.94s/it][AEpoch 8:  92%|█████████▏| 98/106 [04:47<00:23,  2.93s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  87%|████████▋ | 46/53 [01:29<00:13,  1.94s/it][AEpoch 8:  93%|█████████▎| 99/106 [04:49<00:20,  2.92s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  89%|████████▊ | 47/53 [01:31<00:11,  1.94s/it][AEpoch 8:  94%|█████████▍| 100/106 [04:51<00:17,  2.91s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  91%|█████████ | 48/53 [01:33<00:09,  1.94s/it][AEpoch 8:  95%|█████████▌| 101/106 [04:53<00:14,  2.90s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  92%|█████████▏| 49/53 [01:35<00:07,  1.94s/it][AEpoch 8:  96%|█████████▌| 102/106 [04:55<00:11,  2.89s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  94%|█████████▍| 50/53 [01:37<00:05,  1.94s/it][AEpoch 8:  97%|█████████▋| 103/106 [04:57<00:08,  2.88s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  96%|█████████▌| 51/53 [01:39<00:03,  1.94s/it][AEpoch 8:  98%|█████████▊| 104/106 [04:58<00:05,  2.87s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0:  98%|█████████▊| 52/53 [01:40<00:01,  1.94s/it][AEpoch 8:  99%|█████████▉| 105/106 [05:00<00:02,  2.87s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Validation DataLoader 0: 100%|██████████| 53/53 [01:41<00:00,  1.92s/it][AEpoch 8: 100%|██████████| 106/106 [05:01<00:00,  2.85s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]Epoch 8: 100%|██████████| 106/106 [05:01<00:00,  2.85s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0]
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zw9vQctOYH4_0000078.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvTxAShSH_U_0000003.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zyscRpM7c9E_0000016.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvweaacTsTI_0000015.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zyscRpM7c9E_0000018.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvTxAShSH_U_0000002.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zyscRpM7c9E_0000017.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvweaacTsTI_0000017.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zw9vQctOYH4_0000077.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvweaacTsTI_0000018.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zw9vQctOYH4_0000075.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvweaacTsTI_0000016.mp4
                                                                        [AEpoch 8: 100%|██████████| 106/106 [05:01<00:00,  2.85s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 8:   0%|          | 0/106 [00:00<?, ?it/s, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]          Epoch 9:   0%|          | 0/106 [00:00<?, ?it/s, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvTxAShSH_U_0000001.mp4
Epoch 9:   1%|          | 1/106 [00:06<12:02,  6.88s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00361, train/loss_step=1.010, global_step=242.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:   1%|          | 1/106 [00:07<12:44,  7.28s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00553, train/loss_step=1.000, global_step=243.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:   2%|▏         | 2/106 [00:10<08:50,  5.10s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00553, train/loss_step=1.000, global_step=243.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:   2%|▏         | 2/106 [00:10<08:52,  5.12s/it, loss=1, v_num=1, train/loss_simple_step=0.998, train/loss_vlb_step=0.00511, train/loss_step=0.998, global_step=243.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:   3%|▎         | 3/106 [00:12<07:17,  4.25s/it, loss=1, v_num=1, train/loss_simple_step=0.998, train/loss_vlb_step=0.00511, train/loss_step=0.998, global_step=243.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:   3%|▎         | 3/106 [00:13<07:31,  4.38s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.00899, train/loss_step=0.999, global_step=244.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:   4%|▍         | 4/106 [00:16<06:50,  4.02s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.00899, train/loss_step=0.999, global_step=244.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:   4%|▍         | 4/106 [00:16<06:51,  4.03s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00444, train/loss_step=1.000, global_step=244.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:   5%|▍         | 5/106 [00:18<06:16,  3.73s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00444, train/loss_step=1.000, global_step=244.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:   5%|▍         | 5/106 [00:19<06:24,  3.81s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00378, train/loss_step=1.000, global_step=245.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:   6%|▌         | 6/106 [00:21<06:06,  3.66s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00378, train/loss_step=1.000, global_step=245.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:   6%|▌         | 6/106 [00:22<06:06,  3.67s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00455, train/loss_step=1.000, global_step=245.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:   7%|▋         | 7/106 [00:24<05:46,  3.50s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00455, train/loss_step=1.000, global_step=245.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:   7%|▋         | 7/106 [00:24<05:52,  3.56s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.00494, train/loss_step=0.999, global_step=246.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:   8%|▊         | 8/106 [00:27<05:41,  3.49s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.00494, train/loss_step=0.999, global_step=246.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:   8%|▊         | 8/106 [00:27<05:41,  3.49s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00414, train/loss_step=1.000, global_step=246.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:   8%|▊         | 9/106 [00:30<05:27,  3.38s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00414, train/loss_step=1.000, global_step=246.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:   8%|▊         | 9/106 [00:30<05:32,  3.42s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00429, train/loss_step=1.000, global_step=247.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:   9%|▉         | 10/106 [00:33<05:24,  3.38s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00429, train/loss_step=1.000, global_step=247.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:   9%|▉         | 10/106 [00:33<05:24,  3.38s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00536, train/loss_step=1.000, global_step=247.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  10%|█         | 11/106 [00:36<05:13,  3.30s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00536, train/loss_step=1.000, global_step=247.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  10%|█         | 11/106 [00:36<05:16,  3.33s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00475, train/loss_step=1.000, global_step=248.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  11%|█▏        | 12/106 [00:39<05:10,  3.30s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00475, train/loss_step=1.000, global_step=248.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  11%|█▏        | 12/106 [00:39<05:10,  3.30s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00486, train/loss_step=1.000, global_step=248.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  12%|█▏        | 13/106 [00:42<05:01,  3.24s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00486, train/loss_step=1.000, global_step=248.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  12%|█▏        | 13/106 [00:42<05:04,  3.27s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.0219, train/loss_step=1.000, global_step=249.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000] Epoch 9:  13%|█▎        | 14/106 [00:45<04:58,  3.25s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.0219, train/loss_step=1.000, global_step=249.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  13%|█▎        | 14/106 [00:45<04:59,  3.25s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00792, train/loss_step=1.010, global_step=249.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  14%|█▍        | 15/106 [00:48<04:51,  3.20s/it, loss=1, v_num=1, train/loss_simple_step=1.010, train/loss_vlb_step=0.00792, train/loss_step=1.010, global_step=249.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  14%|█▍        | 15/106 [00:48<04:53,  3.23s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.00471, train/loss_step=0.999, global_step=250.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  15%|█▌        | 16/106 [00:51<04:49,  3.21s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.00471, train/loss_step=0.999, global_step=250.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  15%|█▌        | 16/106 [00:51<04:49,  3.21s/it, loss=1, v_num=1, train/loss_simple_step=0.998, train/loss_vlb_step=0.00473, train/loss_step=0.998, global_step=250.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  16%|█▌        | 17/106 [00:53<04:42,  3.17s/it, loss=1, v_num=1, train/loss_simple_step=0.998, train/loss_vlb_step=0.00473, train/loss_step=0.998, global_step=250.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  16%|█▌        | 17/106 [00:54<04:44,  3.20s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00404, train/loss_step=1.000, global_step=251.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  17%|█▋        | 18/106 [00:57<04:40,  3.18s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00404, train/loss_step=1.000, global_step=251.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  17%|█▋        | 18/106 [00:57<04:40,  3.18s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00481, train/loss_step=1.000, global_step=251.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  18%|█▊        | 19/106 [00:59<04:33,  3.15s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00481, train/loss_step=1.000, global_step=251.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  18%|█▊        | 19/106 [01:00<04:35,  3.17s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00563, train/loss_step=1.000, global_step=252.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  19%|█▉        | 20/106 [01:03<04:31,  3.16s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00563, train/loss_step=1.000, global_step=252.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  19%|█▉        | 20/106 [01:03<04:31,  3.16s/it, loss=1, v_num=1, train/loss_simple_step=0.998, train/loss_vlb_step=0.00571, train/loss_step=0.998, global_step=252.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  20%|█▉        | 21/106 [01:05<04:25,  3.13s/it, loss=1, v_num=1, train/loss_simple_step=0.998, train/loss_vlb_step=0.00571, train/loss_step=0.998, global_step=252.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  20%|█▉        | 21/106 [01:06<04:27,  3.15s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00394, train/loss_step=1.000, global_step=253.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  21%|██        | 22/106 [01:09<04:23,  3.14s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00394, train/loss_step=1.000, global_step=253.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  21%|██        | 22/106 [01:09<04:23,  3.14s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.00418, train/loss_step=0.999, global_step=253.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  22%|██▏       | 23/106 [01:11<04:18,  3.11s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.00418, train/loss_step=0.999, global_step=253.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  22%|██▏       | 23/106 [01:11<04:19,  3.13s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00568, train/loss_step=1.000, global_step=254.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  23%|██▎       | 24/106 [01:14<04:15,  3.12s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00568, train/loss_step=1.000, global_step=254.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  23%|██▎       | 24/106 [01:14<04:15,  3.12s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00568, train/loss_step=1.000, global_step=254.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  24%|██▎       | 25/106 [01:17<04:10,  3.10s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00568, train/loss_step=1.000, global_step=254.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  24%|██▎       | 25/106 [01:17<04:12,  3.11s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00407, train/loss_step=1.000, global_step=255.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  25%|██▍       | 26/106 [01:20<04:08,  3.10s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00407, train/loss_step=1.000, global_step=255.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  25%|██▍       | 26/106 [01:20<04:08,  3.11s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.016, train/loss_step=0.999, global_step=255.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]  Epoch 9:  25%|██▌       | 27/106 [01:23<04:03,  3.08s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.016, train/loss_step=0.999, global_step=255.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  25%|██▌       | 27/106 [01:23<04:04,  3.10s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.0114, train/loss_step=0.999, global_step=256.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  26%|██▋       | 28/106 [01:26<04:01,  3.09s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.0114, train/loss_step=0.999, global_step=256.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  26%|██▋       | 28/106 [01:26<04:01,  3.09s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00485, train/loss_step=1.000, global_step=256.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  27%|██▋       | 29/106 [01:29<03:56,  3.07s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00485, train/loss_step=1.000, global_step=256.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  27%|██▋       | 29/106 [01:29<03:57,  3.09s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00537, train/loss_step=1.000, global_step=257.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  28%|██▊       | 30/106 [01:32<03:54,  3.08s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00537, train/loss_step=1.000, global_step=257.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  28%|██▊       | 30/106 [01:32<03:54,  3.08s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00401, train/loss_step=1.000, global_step=257.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  29%|██▉       | 31/106 [01:34<03:49,  3.06s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00401, train/loss_step=1.000, global_step=257.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  29%|██▉       | 31/106 [01:35<03:50,  3.08s/it, loss=1, v_num=1, train/loss_simple_step=0.998, train/loss_vlb_step=0.00808, train/loss_step=0.998, global_step=258.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  30%|███       | 32/106 [01:38<03:47,  3.07s/it, loss=1, v_num=1, train/loss_simple_step=0.998, train/loss_vlb_step=0.00808, train/loss_step=0.998, global_step=258.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  30%|███       | 32/106 [01:38<03:47,  3.07s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.0128, train/loss_step=1.000, global_step=258.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000] Epoch 9:  31%|███       | 33/106 [01:40<03:42,  3.05s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.0128, train/loss_step=1.000, global_step=258.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  31%|███       | 33/106 [01:41<03:43,  3.07s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00784, train/loss_step=1.000, global_step=259.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  32%|███▏      | 34/106 [01:44<03:40,  3.06s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00784, train/loss_step=1.000, global_step=259.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  32%|███▏      | 34/106 [01:44<03:40,  3.06s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00376, train/loss_step=1.000, global_step=259.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  33%|███▎      | 35/106 [01:46<03:36,  3.05s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00376, train/loss_step=1.000, global_step=259.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  33%|███▎      | 35/106 [01:47<03:37,  3.06s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00584, train/loss_step=1.000, global_step=260.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  34%|███▍      | 36/106 [01:49<03:33,  3.05s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00584, train/loss_step=1.000, global_step=260.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  34%|███▍      | 36/106 [01:49<03:33,  3.06s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00593, train/loss_step=1.000, global_step=260.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  35%|███▍      | 37/106 [01:52<03:29,  3.04s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00593, train/loss_step=1.000, global_step=260.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  35%|███▍      | 37/106 [01:52<03:30,  3.05s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00569, train/loss_step=1.000, global_step=261.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  36%|███▌      | 38/106 [01:55<03:27,  3.05s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00569, train/loss_step=1.000, global_step=261.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  36%|███▌      | 38/106 [01:55<03:27,  3.05s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00427, train/loss_step=1.000, global_step=261.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  37%|███▋      | 39/106 [01:58<03:23,  3.03s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00427, train/loss_step=1.000, global_step=261.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  37%|███▋      | 39/106 [01:58<03:23,  3.04s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00486, train/loss_step=1.000, global_step=262.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  38%|███▊      | 40/106 [02:01<03:20,  3.04s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00486, train/loss_step=1.000, global_step=262.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  38%|███▊      | 40/106 [02:01<03:20,  3.04s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00438, train/loss_step=1.000, global_step=262.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  39%|███▊      | 41/106 [02:04<03:16,  3.03s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00438, train/loss_step=1.000, global_step=262.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  39%|███▊      | 41/106 [02:04<03:17,  3.04s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00466, train/loss_step=1.000, global_step=263.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  40%|███▉      | 42/106 [02:07<03:14,  3.04s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00466, train/loss_step=1.000, global_step=263.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  40%|███▉      | 42/106 [02:07<03:14,  3.04s/it, loss=1, v_num=1, train/loss_simple_step=0.998, train/loss_vlb_step=0.00433, train/loss_step=0.998, global_step=263.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  41%|████      | 43/106 [02:10<03:10,  3.02s/it, loss=1, v_num=1, train/loss_simple_step=0.998, train/loss_vlb_step=0.00433, train/loss_step=0.998, global_step=263.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  41%|████      | 43/106 [02:10<03:11,  3.03s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00399, train/loss_step=1.000, global_step=264.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  42%|████▏     | 44/106 [02:13<03:07,  3.03s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00399, train/loss_step=1.000, global_step=264.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  42%|████▏     | 44/106 [02:13<03:07,  3.03s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00437, train/loss_step=1.000, global_step=264.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  42%|████▏     | 45/106 [02:15<03:04,  3.02s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00437, train/loss_step=1.000, global_step=264.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  42%|████▏     | 45/106 [02:16<03:04,  3.03s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00512, train/loss_step=1.000, global_step=265.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  43%|████▎     | 46/106 [02:19<03:01,  3.03s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00512, train/loss_step=1.000, global_step=265.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  43%|████▎     | 46/106 [02:19<03:01,  3.03s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00424, train/loss_step=1.000, global_step=265.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  44%|████▍     | 47/106 [02:21<02:57,  3.02s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00424, train/loss_step=1.000, global_step=265.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  44%|████▍     | 47/106 [02:22<02:58,  3.02s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00462, train/loss_step=1.000, global_step=266.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  45%|████▌     | 48/106 [02:25<02:55,  3.02s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00462, train/loss_step=1.000, global_step=266.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  45%|████▌     | 48/106 [02:25<02:55,  3.02s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00619, train/loss_step=1.000, global_step=266.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  46%|████▌     | 49/106 [02:27<02:51,  3.01s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00619, train/loss_step=1.000, global_step=266.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  46%|████▌     | 49/106 [02:27<02:52,  3.02s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00413, train/loss_step=1.000, global_step=267.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  47%|████▋     | 50/106 [02:30<02:49,  3.02s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00413, train/loss_step=1.000, global_step=267.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  47%|████▋     | 50/106 [02:30<02:49,  3.02s/it, loss=1, v_num=1, train/loss_simple_step=0.997, train/loss_vlb_step=0.0158, train/loss_step=0.997, global_step=267.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000] Epoch 9:  48%|████▊     | 51/106 [02:33<02:45,  3.01s/it, loss=1, v_num=1, train/loss_simple_step=0.997, train/loss_vlb_step=0.0158, train/loss_step=0.997, global_step=267.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  48%|████▊     | 51/106 [02:33<02:45,  3.02s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.00542, train/loss_step=0.999, global_step=268.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  49%|████▉     | 52/106 [02:36<02:42,  3.01s/it, loss=1, v_num=1, train/loss_simple_step=0.999, train/loss_vlb_step=0.00542, train/loss_step=0.999, global_step=268.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  49%|████▉     | 52/106 [02:36<02:42,  3.02s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00543, train/loss_step=1.000, global_step=268.0, train/loss_siLoad video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvweaacTsTI_0000018.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zw9vQctOYH4_0000075.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvTxAShSH_U_0000002.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvweaacTsTI_0000017.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zyscRpM7c9E_0000016.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zyscRpM7c9E_0000018.mp4
mple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  50%|█████     | 53/106 [02:38<02:38,  2.98s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00543, train/loss_step=1.000, global_step=268.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9:  50%|█████     | 53/106 [02:38<02:38,  2.98s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zw9vQctOYH4_0000077.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zyscRpM7c9E_0000017.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvweaacTsTI_0000015.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvweaacTsTI_0000016.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zw9vQctOYH4_0000078.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvTxAShSH_U_0000003.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvTxAShSH_U_0000001.mp4

Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/53 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/53 [00:00<?, ?it/s][A
Validation DataLoader 0:   2%|▏         | 1/53 [00:04<03:52,  4.48s/it][AEpoch 9:  51%|█████     | 54/106 [02:57<02:51,  3.29s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:   4%|▍         | 2/53 [00:06<02:44,  3.23s/it][AEpoch 9:  52%|█████▏    | 55/106 [02:59<02:46,  3.27s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:   6%|▌         | 3/53 [00:08<02:19,  2.79s/it][AEpoch 9:  53%|█████▎    | 56/106 [03:01<02:42,  3.25s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:   8%|▊         | 4/53 [00:10<02:06,  2.58s/it][AEpoch 9:  54%|█████▍    | 57/106 [03:03<02:37,  3.22s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:   9%|▉         | 5/53 [00:12<01:57,  2.45s/it][AEpoch 9:  55%|█████▍    | 58/106 [03:05<02:33,  3.20s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  11%|█▏        | 6/53 [00:14<01:52,  2.39s/it][AEpoch 9:  56%|█████▌    | 59/106 [03:07<02:29,  3.18s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  13%|█▎        | 7/53 [00:16<01:46,  2.32s/it][AEpoch 9:  57%|█████▋    | 60/106 [03:09<02:25,  3.16s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  15%|█▌        | 8/53 [00:18<01:42,  2.27s/it][AEpoch 9:  58%|█████▊    | 61/106 [03:11<02:21,  3.14s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  17%|█▋        | 9/53 [00:20<01:38,  2.24s/it][AEpoch 9:  58%|█████▊    | 62/106 [03:13<02:17,  3.12s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  19%|█▉        | 10/53 [00:22<01:34,  2.20s/it][AEpoch 9:  59%|█████▉    | 63/106 [03:15<02:13,  3.10s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  21%|██        | 11/53 [00:24<01:31,  2.18s/it][AEpoch 9:  60%|██████    | 64/106 [03:17<02:09,  3.08s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  23%|██▎       | 12/53 [00:25<01:28,  2.16s/it][AEpoch 9:  61%|██████▏   | 65/106 [03:19<02:05,  3.07s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  25%|██▍       | 13/53 [00:27<01:25,  2.15s/it][AEpoch 9:  62%|██████▏   | 66/106 [03:21<02:01,  3.05s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  26%|██▋       | 14/53 [00:29<01:23,  2.13s/it][AEpoch 9:  63%|██████▎   | 67/106 [03:23<01:58,  3.03s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  28%|██▊       | 15/53 [00:31<01:20,  2.12s/it][AEpoch 9:  64%|██████▍   | 68/106 [03:25<01:54,  3.02s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  30%|███       | 16/53 [00:33<01:18,  2.11s/it][AEpoch 9:  65%|██████▌   | 69/106 [03:27<01:51,  3.00s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  32%|███▏      | 17/53 [00:35<01:15,  2.10s/it][AEpoch 9:  66%|██████▌   | 70/106 [03:29<01:47,  2.99s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  34%|███▍      | 18/53 [00:37<01:13,  2.09s/it][AEpoch 9:  67%|██████▋   | 71/106 [03:31<01:44,  2.97s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  36%|███▌      | 19/53 [00:39<01:10,  2.08s/it][AEpoch 9:  68%|██████▊   | 72/106 [03:32<01:40,  2.96s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  38%|███▊      | 20/53 [00:41<01:08,  2.08s/it][AEpoch 9:  69%|██████▉   | 73/106 [03:34<01:37,  2.94s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  40%|███▉      | 21/53 [00:43<01:06,  2.07s/it][AEpoch 9:  70%|██████▉   | 74/106 [03:36<01:33,  2.93s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  42%|████▏     | 22/53 [00:45<01:04,  2.07s/it][AEpoch 9:  71%|███████   | 75/106 [03:38<01:30,  2.92s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  43%|████▎     | 23/53 [00:47<01:01,  2.06s/it][AEpoch 9:  72%|███████▏  | 76/106 [03:40<01:27,  2.90s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  45%|████▌     | 24/53 [00:49<00:59,  2.06s/it][AEpoch 9:  73%|███████▎  | 77/106 [03:42<01:23,  2.89s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  47%|████▋     | 25/53 [00:51<00:57,  2.05s/it][AEpoch 9:  74%|███████▎  | 78/106 [03:44<01:20,  2.88s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  49%|████▉     | 26/53 [00:53<00:55,  2.05s/it][AEpoch 9:  75%|███████▍  | 79/106 [03:46<01:17,  2.87s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  51%|█████     | 27/53 [00:55<00:53,  2.04s/it][AEpoch 9:  75%|███████▌  | 80/106 [03:48<01:14,  2.86s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  53%|█████▎    | 28/53 [00:57<00:50,  2.04s/it][AEpoch 9:  76%|███████▋  | 81/106 [03:50<01:11,  2.84s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  55%|█████▍    | 29/53 [00:58<00:48,  2.03s/it][AEpoch 9:  77%|███████▋  | 82/106 [03:52<01:08,  2.83s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  57%|█████▋    | 30/53 [01:00<00:46,  2.03s/it][AEpoch 9:  78%|███████▊  | 83/106 [03:54<01:04,  2.82s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  58%|█████▊    | 31/53 [01:02<00:44,  2.03s/it][AEpoch 9:  79%|███████▉  | 84/106 [03:56<01:01,  2.81s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  60%|██████    | 32/53 [01:04<00:42,  2.02s/it][AEpoch 9:  80%|████████  | 85/106 [03:58<00:58,  2.80s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  62%|██████▏   | 33/53 [01:06<00:40,  2.02s/it][AEpoch 9:  81%|████████  | 86/106 [04:00<00:55,  2.79s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  64%|██████▍   | 34/53 [01:08<00:38,  2.02s/it][AEpoch 9:  82%|████████▏ | 87/106 [04:02<00:52,  2.78s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  66%|██████▌   | 35/53 [01:10<00:36,  2.02s/it][AEpoch 9:  83%|████████▎ | 88/106 [04:03<00:49,  2.77s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  68%|██████▊   | 36/53 [01:12<00:34,  2.01s/it][AEpoch 9:  84%|████████▍ | 89/106 [04:05<00:46,  2.76s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  70%|██████▉   | 37/53 [01:14<00:32,  2.01s/it][AEpoch 9:  85%|████████▍ | 90/106 [04:07<00:44,  2.75s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  72%|███████▏  | 38/53 [01:16<00:30,  2.01s/it][AEpoch 9:  86%|████████▌ | 91/106 [04:09<00:41,  2.74s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  74%|███████▎  | 39/53 [01:18<00:28,  2.01s/it][AEpoch 9:  87%|████████▋ | 92/106 [04:11<00:38,  2.74s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  75%|███████▌  | 40/53 [01:20<00:26,  2.01s/it][AEpoch 9:  88%|████████▊ | 93/106 [04:13<00:35,  2.73s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  77%|███████▋  | 41/53 [01:22<00:24,  2.00s/it][AEpoch 9:  89%|████████▊ | 94/106 [04:15<00:32,  2.72s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  79%|███████▉  | 42/53 [01:24<00:22,  2.00s/it][AEpoch 9:  90%|████████▉ | 95/106 [04:17<00:29,  2.71s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  81%|████████  | 43/53 [01:26<00:20,  2.00s/it][AEpoch 9:  91%|█████████ | 96/106 [04:19<00:27,  2.70s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  83%|████████▎ | 44/53 [01:27<00:17,  2.00s/it][AEpoch 9:  92%|█████████▏| 97/106 [04:21<00:24,  2.69s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  85%|████████▍ | 45/53 [01:29<00:15,  2.00s/it][AEpoch 9:  92%|█████████▏| 98/106 [04:23<00:21,  2.69s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  87%|████████▋ | 46/53 [01:31<00:13,  2.00s/it][AEpoch 9:  93%|█████████▎| 99/106 [04:25<00:18,  2.68s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  89%|████████▊ | 47/53 [01:33<00:11,  1.99s/it][AEpoch 9:  94%|█████████▍| 100/106 [04:27<00:16,  2.67s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  91%|█████████ | 48/53 [01:35<00:09,  1.99s/it][AEpoch 9:  95%|█████████▌| 101/106 [04:29<00:13,  2.66s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  92%|█████████▏| 49/53 [01:37<00:07,  1.99s/it][AEpoch 9:  96%|█████████▌| 102/106 [04:30<00:10,  2.66s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  94%|█████████▍| 50/53 [01:39<00:05,  1.99s/it][AEpoch 9:  97%|█████████▋| 103/106 [04:32<00:07,  2.65s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  96%|█████████▌| 51/53 [01:41<00:03,  1.99s/it][AEpoch 9:  98%|█████████▊| 104/106 [04:34<00:05,  2.64s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0:  98%|█████████▊| 52/53 [01:43<00:01,  1.99s/it][AEpoch 9:  99%|█████████▉| 105/106 [04:36<00:02,  2.64s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Validation DataLoader 0: 100%|██████████| 53/53 [01:44<00:00,  1.97s/it][AEpoch 9: 100%|██████████| 106/106 [04:37<00:00,  2.62s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]Epoch 9: 100%|██████████| 106/106 [04:37<00:00,  2.62s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00618, train/loss_epoch=1.000]
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zw9vQctOYH4_0000077.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvweaacTsTI_0000017.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvTxAShSH_U_0000001.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvweaacTsTI_0000018.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zyscRpM7c9E_0000017.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvweaacTsTI_0000016.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zyscRpM7c9E_0000018.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zw9vQctOYH4_0000075.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvTxAShSH_U_0000002.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zyscRpM7c9E_0000016.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvTxAShSH_U_0000003.mp4
Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zvweaacTsTI_0000015.mp4
                                                                        [AEpoch 9: 100%|██████████| 106/106 [04:37<00:00,  2.62s/it, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00608, train/loss_epoch=1.000]Epoch 9:   0%|          | 0/106 [00:00<?, ?it/s, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00608, train/loss_epoch=1.000]          Epoch 10:   0%|          | 0/106 [00:00<?, ?it/s, loss=1, v_num=1, train/loss_simple_step=1.000, train/loss_vlb_step=0.00425, train/loss_step=1.000, global_step=269.0, train/loss_simple_epoch=1.000, train/loss_vlb_epoch=0.00608, train/loss_epoch=1.000]Load video failed! path = /aifs4su/mmdata/rawdata/videogen/macvid/video_dataset_85/zw9vQctOYH4_0000078.mp4
